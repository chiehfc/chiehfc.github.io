
<!DOCTYPE html>
<html data-brackets-id='1'>

<head data-brackets-id='2'>
    <meta data-brackets-id='3' charset="utf-8">
    <meta data-brackets-id='4' http-equiv="X-UA-Compatible" content="IE=edge">
    <title data-brackets-id='5'>Yu Zhu</title>
    <meta data-brackets-id='6' name="description" content="Yu Zhu personal page at wvu">
    <link data-brackets-id='7' rel="stylesheet" href="main.css">
</head>

<body data-brackets-id='8'>

    <!--<h1 data-brackets-id='9'>Yu Zhu<img src="https://sites.google.com/site/csyuzhu/_/rsrc/1409528678001/home/18ea1fe.jpg" alt="profile" align="right"style="width:200px;height:200px;"></h1>
-->
    <img src="photo.jpg" alt="profile" align="right" style="width:30%;height:30%;">
    <h1 data-brackets-id='9'>Yu Zhu</h1>
    <h2 data-brackets-id='9'>Research Engineer @ Novumind </h2>
    <h2 data-brackets-id='9'>Ph.D. in Computer Science</h2>
    <br>
    <a href="http://www.lcsee.cemr.wvu.edu/" target="_blank"><h4 data-brackets-id='9'> Lane Department of Computer Science and Electrical Engineering </h4></a>
    <h4 data-brackets-id='9'>West Virginia University, WV, USA</h4>
    <br>
    <h4 data-brackets-id='10'>Email: yuzhu(at)novumind(dot)com </h4>
    <h4>LinkedIn Profile: <a href="https://www.linkedin.com/in/csyuzhu/" target="_blank">here</a></h4>

    <h4>Google Scholar: <a href="https://scholar.google.com/citations?user=6JGZgcwAAAAJ&hl=en" target="_blank">here</a></h4>

    <br>


    <!--
            What's new
        -->
    <h3 data-brackets-id='9'>What's new</h3>
    <ul data-brackets-id='48'>
        
         <li data-brackets-id='62'><font size="3" color="red">~New~</font><b> Paper "Still to Video Face Matching Using Multiple Geodesic Flows" accepted by IEEE Trans. on Information Forensics & Security (TIFS). </b></li>
        
        
        <li data-brackets-id='62'><font size="3" color="red">~New~</font><b> Paper “Exploring Deep Features with Different Distance Measures for Still to Video Face Matching,” to appear at the CCBR2016, October 2016, Chengdu, China </b> </li>
        <li data-brackets-id='62'><font size="3" color="red">~New~</font><b> Paper “Report on the BTAS 2016
Video Person Recognition Evaluation,” to appear at the BTAS 2016, September 2016, Niagara, NY </b> </li>
        <li data-brackets-id='62'><font size="3" color="red">~New~</font><b>  We have achieved 1st rank (Track 2) and 2nd rank (Track 1) in the Person Recognition Challenge @ BTAS 2016. </b> </li>
        <li data-brackets-id='62'>  Ph.D defended! </b> </li>
        <li data-brackets-id='62'> Paper Accepted</b> @ ICCVW 2015 - "A Study on Apparent Age Estimation", ICCVW 2015.</li>
        <li data-brackets-id='62'> We are the <b>3rd winner</b> of Age Estimation Challenge on <a href="http://gesture.chalearn.org/">ChaLearn LaP(Looking at People) Challenge @ ICCV2015</a></li>
        <li data-brackets-id='49'> <a data-brackets-id='50' href="http://yucoding.blogspot.com/" target="_blank">Coding Blog</a> Page Views over 800,000</li>
        <li data-brackets-id='61'><b>  Paper Accepted</b> @ BTAS 2015 - "Still to Video Face Recognition Using a Heterogeneous Matching Approach", BTAS 2015.</li>
        <li data-brackets-id='51'> One Co-authored paper is accepted by IEEE Transactions on Information Forensics and Security(TIFS)!</li>
        <li data-brackets-id='55'>Sharing Software: Facial Labeling Application <a href="/face_label_code_python.rar" target="_blank">(download)</a></li>
        <li data-brackets-id='57'>Our published Paper: Evaluating Spatiotemporal Interest Point Features for Depth-based Action Recognition" has <b>ranked 7th on "Most Downloaded Image and Vision Computing(IVC) Articles" </b> </li>
        <li data-brackets-id='59'>Android App <b><a href="/cvpr14_poster_demo_final_small.png" target="_blank">Demoed @ CVPR 2014</b></a>
            Facial Analysis for Body Mass Index (BMI) Estimation on Mobile Device Demoed at CVPR 2014 conference!!!</li>
        <li data-brackets-id='53'><a data-brackets-id='50' href="http://yucoding.blogspot.com/" target="_blank">Coding Blog</a> Page Views over 200,000</li>
        <li data-brackets-id='61'><b>Ph.D. Candidacy Exam Passed!</b> Now as a Ph.D. Candidate at LCSEE department, WVU</li>
        <li data-brackets-id='61'><b>Paper Accepted!</b> "Fusing multiple features for depth-based action recognition", ACM-TIST.</li>
        <li data-brackets-id='61'>Ph.D. Qualifying Exam Passed at LCSEE, WVU </li>
        <li data-brackets-id='61'>Paper published! "A Study on Visible to Infrared Action Recognition" has been published in Signal Processing Letters, IEEE</li>

    </ul>

    <br>

    <!--
            Short Bio
        -->
    <h3 data-brackets-id='9'>Short Bio</h3>
    <p style="text-indent: 2em" data-brackets-id='11'>
        My name is <b>Zhu, Yu (朱 欤)</b>. Currently I am a Ph.D. candidate in Computer Science at <a href="http://www.lcsee.cemr.wvu.edu/" target="_blank">LCSEE department</a>, <a href="http://www.wvu.edu/" target="_blank">West Virginia University</a>, USA. I'm working as a Graduate Research Assistant (GRA) in Computer Vision Lab.</p>
    <p style="text-indent: 2em">My research supervisor is <a href="http://www.csee.wvu.edu/~gdguo/" target="_blank">Dr. Guodong Guo</a>.
    </p>


    <br>
    <!--
            Research Interest
        -->
    <h3 data-brackets-id='9'>Research Interests</h3>
    <p style="text-indent: 2em" data-brackets-id='12'>
        <em data-brackets-id='13'>Pattern Recognition, Machine Learning, Computer Vision, Face Recognition, Action Recognition, Biometrics, Deep Learning</em>
    </p>
    <p style="text-indent: 2em"> I am also highly interested in programming and software engineering, e.g., LAMP, Android, Python, C/C++, etc. </p>

    <!--
            Education
        -->
    <br>

    <h3 data-brackets-id='14'>Education</h3>
    <p>
        <dl>
            <dt> <b>Ph.D.</b> in Computer Science, <em>(In progress)</em>, <b>GPA 4.0/4.0</b> West Virginia University, WV, USA </dt>
            <dd>- Graduate Research Assistant, in Computer Vision Lab. </dd>
            <br>

            <dt> <b>B.E.</b> in Software Engineering, 2010, <b>GPA 3.4/4.0</b> Northwestern Polytechnical University, Xi'an, China</dt>
            <dd>- Teaching Assistant (TA) of course ‘User-Centered Design and Testing’ 2009.9-2010.2</dd>
            <dd>- Teaching Assistant (TA) of course ‘Introduction to Computer Systems’ 2009.3-2009.6</dd>
        </dl>
    </p>
    <br>


    <!--
           Publications
        -->
    <h3 data-brackets-id='17'>Publications (Graduate) </h3>
    
     <p>
        <b>Yu Zhu</b>; Y. Li, G. Mu, S. Shan, and G-D. Guo, "Still to Video Face Matching Using Multiple Geodesic Flows", IEEE Trans. on Information Forensics & Security(TIFS), accepted Aug 2016.
    </p>
    
    <p>
        <b>Yu Zhu</b>; and Guodong Guo. "Exploring Deep Features with Different Distance Measures for Still to Video Face Matching ", CCBR, 2016.
    </p>
    
    <p>
        Report on the BTAS 2016 Video Person Recognition Evaluation ", BTAS, 2016
    </p>
    
    <p>
        <b>Yu Zhu</b>; et al. "A Study on Apparent Age Estimation ", ICCV LAP Workshop, 2015.
        <b>[<a href="/paper/zhu_apparent_age_ICCVW15.pdf" target="_blank">PDF</a>]</b>
    </p>
    
    <p>
        <b>Yu Zhu</b>; et al. "Still to Video Face Recognition Using a Heterogeneous Matching Approach" IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS), 2015.
        <b>[<a href="/paper/zhu_s2v_btas.pdf" target="_blank">PDF</a>]</b>
    </p>

    <p>
        <b>Yu Zhu</b>; Wenbin Chen, and Guodong Guo. "Fusing Multiple Features for Depth-Based Action Recognition." <i>ACM Transactions on Intelligent Systems and Technology (TIST)</i> 6.2 (2015): 18.
        <b>[<a href="/paper/zhu_rgbdaction_tist.pdf" target="_blank">PDF</a>]</b>
    </p>
    <p>
        <b>Yu Zhu</b>; Wenbin Chen; Guodong Guo, "Evaluating spatiotemporal interest point features for depth-based action recognition", <i>Image and Vision Computing (IVC)</i>, Volume 32, Issue 8, August 2014, Pages 453-464. 
        <b>[<a href="/paper/Zhu_Evaluating_IVC.pdf" target="_blank">PDF</a>]</b>
    </p>
    <p data-brackets-id='18'>
        <b>Yu Zhu</b>; Guodong Guo, "A Study on Visible to Infrared Action Recognition," <i>IEEE Signal Processing Letters (SPL) </i>, vol.20, no.9, pp.897,900, Sept. 2013. 
        <b>[<a href="/paper/zhu_ir_spl.pdf" target="_blank">PDF</a>]</b>
    </p>
    <p>
        <b>Yu Zhu</b>; Wenbin Chen; Guodong Guo, "Fusing Spatiotemporal Features and Joints for 3D Action Recognition," <i>IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2013</i> , vol., no., pp.486,491, 23-28 June 2013
        <b>[<a href="/paper/Zhu_Fusing_Spatiotemporal_Features_2013_CVPR_paper.pdf" target="_blank">PDF</a>]</b>
    </p>


    <p>
        L. Wen, X.Li, G, Guo and <b>Y, Zhu</b>, “Automated Depression Diagnosis based on Facial Dynamic Analysis and Sparse Coding.” <i>IEEE Transactions on Information Forensics & Security (TIFS)</i> 2015
    </p>

    <br>

    <!--
           Awards
        -->
    <h3 data-brackets-id='17'>Awards </h3>
    <p><li data-brackets-id='62'><font size="3" color="red"> </font>  Rank 1st (Track 2) and Rank 2nd (Track 1) of Person Recognition Challenge @ BTAS2016</a></li> </b></a></p>
    <p><li data-brackets-id='62'><font size="3" color="red"> </font>  Rank 4th of Age Estimation Challenge on <a href="http://gesture.chalearn.org/">ChaLearn LaP(Looking at People) Challenge @ CVPR2016</a></li> </b></a></p>
    <p><li data-brackets-id='62'><font size="3" color="red"> </font>  Rank 3rd of Age Estimation Challenge on <a href="http://gesture.chalearn.org/">ChaLearn LaP(Looking at People) Challenge @ ICCV2015</a></li> </b></a></p>

    <br>

    <!--
           Presentation
        -->
    <h3 data-brackets-id='17'>Presentation </h3>
    <p><b>Yu Zhu</b>, Lingyun Wen, Guodong Guo, "Facial Analysis for Body Mass Index (BMI) Estimation on Mobile Device" <b><i>Demo presentation at CVPR 2014</i></b>.
        <a href="/cvpr14_poster_demo_final_small.png" target="_blank">Poster</b></a></p>

    <br>
    <!--
           Publications (undergraduate)
        -->
    <h3 data-brackets-id='17'>Publications (Undergraduate) </h3>
    <p>
        <b>Zhu Yu;</b> et al., "A chaos-based image encryption algorithm using wavelet transform," 2010 2nd Intl. Conference on Advanced Computer Control (ICACC), vol.2, no., pp.217,222, 2010
        <b>[<a href="/paper/zhu_chaos.pdf" target="_blank">PDF</a>]</b>
    </p>
    <p>Zhang Yunpeng; <b>Zhu Yu</b>; et al., "Index-based symmetric DNA encryption algorithm," 2011 4th Intl. Congress on Image and Signal Processing (CISP), vol.5, no., pp.2290,2294, 2011
        <b>[<a href="/paper/zhu_index.pdf" target="_blank">PDF</a>]</b>
</p>

    <p>Zhou Zhe; Yang Haibing; <b>Zhu Yu</b>; et al., "A Block Encryption Scheme Based on 3D Chaotic Arnold Maps," ASIA '09. Intl. Asia Symposium on Intelligent Interaction and Affective Computing, 2009. vol., no., pp.15,20</p>

    <br>
    <!--
            Paper review
        -->
    <h3 data-brackets-id='29'>Professional Activities:</h3>
    <ul data-brackets-id='48'>
        <li data-brackets-id='49'>
            Reviewer for Computer Vision and Image Understanding(CVIU) (2015)
        </li>
         <li data-brackets-id='49'>
            Reviewer for IEEE Transactions on Human-Machine Systems (THMS) (2015)
        </li>
    </ul>


    <br>

    <!--
            Programming Skills
        -->
    <h3 data-brackets-id='33'>Programming Skills:</h3>
    <ul data-brackets-id='48'>
        <li data-brackets-id='49'>
            C/C++, OpenCV, cudaC
        </li>
        <li data-brackets-id='49'>
            Java, Android
        </li>
        <li data-brackets-id='49'>
            Python, numpy/scipy, scikit-learn, caffe
        </li>
        <li data-brackets-id='49'>
            Matlab, Torch7, Linux/Shell, LAMP, Git
        </li>
    </ul>



    <br>
    <!--
           Blog
        -->

    <h3 data-brackets-id='33'>Tech Blogs:</h3>
    <p style="text-indent: 2em" data-brackets-id='38' class="note">
        <a href="http://yucoding.blogspot.com/" target="_blank">Yu's Coding Garden</a> (Algorithm/Data Structure)
    </p>
   <!-- <p style="text-indent: 2em" data-brackets-id='38' class="note">
        <a href="http://yulearning.blogspot.com/" target="_blank">Yu's Machine Learning Garden </a> (machine learning related)
    </p>
    -->
    <br>

    <!--
          Software
        -->
    <h3 data-brackets-id='39'>Software:</h3>
    <p data-brackets-id='40'>
        <dl>
            <dt>- Facial Labeling Application <a href="/face_label_code_python.rar" target="_blank">(download)</a> </dt>
            <dd>- This software is for manually labeling facial points (landmarks) on facial images.</dd>
            <dd>- Written in Python with Tkinter (python GUI lib) and PIL</dd>
            <dd>- To use on Windows and MAC: use py2exe, py2app or pyInstaller, which provide an easy way for packaging this application to standalone version. </dd>
        </dl>
    </p>

    <br>

    <!--
           Coursera
        -->
    <h3 data-brackets-id='43'>Certifications of Coursera Online Courses:</h3>
    <p data-brackets-id='44'>
        <dl>
            <dt>- Heterogeneous Parallel Programming</dt>
            <dd><a href="/coursera/Coursera_hetero_2015.pdf" target="_blank">Statement of Accomplishment</a></dd>
        </dl>
    </p>
    <p data-brackets-id='44'>
        <dl>
            <dt>- Programming Mobile Applications for Android Handheld Systems </dt>
            <dd><a href="/coursera/Coursera_android_2015.pdf" target="_blank">Statement of Accomplishment</a></dd>
        </dl>
    </p>
    <p data-brackets-id='44'>
        <dl>
            <dt>- Machine Learning</dt>
            <dd><a href="/coursera/Coursera_ml_2015.pdf" target="_blank">Statement of Accomplishment</a></dd>
        </dl>
    </p>
    <p data-brackets-id='44'>
        <dl>
            <dt>- Programming for Everybody (Python) </dt>
            <dd><a href="/coursera/Coursera_pythonlearn_2015.pdf" target="_blank">Statement of Accomplishment</a></dd>
        </dl>
    </p>
    <p data-brackets-id='44'>
        <dl>
            <dt>- Image and video processing: From Mars to Hollywood with a stop at the hospital</dt>
            <dd><a href="/coursera/Coursera_images_2015.pdf" target="_blank">Statement of Accomplishment</a></dd>
        </dl>
    </p>


    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>

    <!--
            Useful Links
        -->
    <h4 data-brackets-id='46'>Useful Links:</h4>
    <ul data-brackets-id='48'>
        <li data-brackets-id='49'><a data-brackets-id='50' href="http://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial" target="_blank">Deep learning Tutorial</a></li>
        <li data-brackets-id='51'><a data-brackets-id='52' href="http://caffe.berkeleyvision.org/" target="_blank">Deep Learning Caffe</a></li>
        <li data-brackets-id='53'><a data-brackets-id='54' href="http://vision.ucsd.edu/~pdollar/toolbox/doc/" target="_blank">Piotr's Toolbox</a></li>
        <li data-brackets-id='55'><a data-brackets-id='56' href="http://www.cs.man.ac.uk/~gbrown/fstoolbox/" target="_blank">FEAST Toolbox</a></li>
        <li data-brackets-id='57'><a data-brackets-id='58' href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank">LibSVM</a></li>
        <li data-brackets-id='59'><a data-brackets-id='60' href="http://www.vlfeat.org/" target="_blank">VLFeat</a></li>
        <li data-brackets-id='61'><a data-brackets-id='62' href="http://www.vlfeat.org/matconvnet/" target="_blank">MatConvNet</a></li>

    </ul>


    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <center>
        <p data-brackets-id='46'><em>Last updated on 2016.8</em></p>
    </center>

</body>

</html>
